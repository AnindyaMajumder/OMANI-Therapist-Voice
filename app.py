import streamlit as st
import tempfile

from audio_recorder_streamlit import audio_recorder
from src.transcribe_whisper import transcribe_audio  
from src.response import response
from src.tts import text_to_speech

if "texts" not in st.session_state:
    st.session_state["texts"] = [
        {
            "role": "system",
            "content": (
                "Ø£Ù†Øª Ø£Ø®ØµØ§Ø¦ÙŠ ØµØ­Ø© Ù†ÙØ³ÙŠØ© Ù…ØªØ¹Ø§Ø·Ù. Ø§Ø³ØªÙ…Ø¹ Ø¨Ø¹Ù†Ø§ÙŠØ© Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ ÙˆØ±Ø¯ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©. "
                "ÙƒÙ† Ù…ÙˆØ¬Ø²Ù‹Ø§ØŒ Ù…Ø´Ø¬Ø¹Ù‹Ø§ØŒ ÙˆÙ‚Ø¯Ù… Ø¯Ø¹Ù…Ù‹Ø§ Ù†ÙØ³ÙŠÙ‹Ø§ Ø¯Ø§ÙØ¦Ù‹Ø§ ÙÙŠ ÙƒÙ„ Ø¥Ø¬Ø§Ø¨Ø©."
            )
        }
    ]
texts = st.session_state["texts"]
text = ""

def recording():
    st.markdown("### ğŸ¤ Record your voice below")
    audio_bytes = audio_recorder(
        text="Click to record",
        icon_size="2x",
        pause_threshold=2.0,
        sample_rate=16000
    )
    if audio_bytes:
        st.success("Audio recorded! ğŸ‰")
        st.audio(audio_bytes, format="audio/wav")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_bytes)
            st.session_state["temp_wav_path"] = tmp_file.name
        st.session_state["audio_ready"] = True
    else:
        st.session_state["audio_ready"] = False

if __name__ == "__main__":
    st.set_page_config(page_title="OMANI Therapist Voice", page_icon="ğŸ§‘â€âš•ï¸", layout="centered")
    st.title("ğŸ§‘â€âš•ï¸ Therapist Voice")
    st.markdown(
        """
        <style>
        .stTabs [data-baseweb="tab"] { font-size: 1.2rem; }
        </style>
        """,
        unsafe_allow_html=True,
    )

    tab1, = st.tabs(["ğŸ™ï¸ Audio Input"])
    with tab1:
        recording()

    if st.session_state.get("audio_ready", False):
        st.header("ğŸ“ Transcript")
        with st.spinner("Transcribing audio..."):
            print(f"Transcribing audio from: {st.session_state['temp_wav_path']}")
            transcript = transcribe_audio(st.session_state["temp_wav_path"])
        for segment in transcript:
            st.write(f"**[{segment.start:.2f}s â†’ {segment.end:.2f}s]** {segment.text.strip()}")
            text += str(segment.text)

        st.header("ğŸ¤– Response")
        with st.spinner("Generating response..."):
            texts.append({
                "role": "user",
                "content": text
            })
            response_text = response(texts)
            texts.append({
                "role": "assistant",
                "content": response_text
            })
            st.session_state["texts"] = texts
            text = ""
        st.write(response_text)
        print(f"Response generated: {texts}")
        # Generate and play voice response using gTTS
        with st.spinner("Generating voice response..."):
            audio_data = text_to_speech(response_text, lang='ar')
            if audio_data:
                st.audio(audio_data, format="audio/mp3")
            else:
                st.warning("Could not generate voice response.")

        # Display chat history
        st.header("ğŸ’¬ Chat History")
        for msg in texts:
            if msg["role"] == "user":
                st.markdown(f"<div style='color:blue'><b>ğŸ‘¤ User:</b> {msg['content']}</div>", unsafe_allow_html=True)
            elif msg["role"] == "assistant":
                st.markdown(f"<div style='color:green'><b>ğŸ¤– Therapist:</b> {msg['content']}</div>", unsafe_allow_html=True)

    print("Done with processing!")